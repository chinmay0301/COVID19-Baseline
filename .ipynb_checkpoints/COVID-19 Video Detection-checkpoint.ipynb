{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Headshot.mp4')\n",
    "\n",
    "ret, frame = cap.read()\n",
    "frame = imutils.rotate_bound(frame,90)\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_cascade.detectMultiScale(frame, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    img = cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0,),2)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0,   0,   0],\n",
       "        [138, 182, 198],\n",
       "        [138, 182, 198],\n",
       "        ...,\n",
       "        [131, 175, 191],\n",
       "        [131, 175, 191],\n",
       "        [133, 177, 193]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [138, 182, 198],\n",
       "        [138, 182, 198],\n",
       "        ...,\n",
       "        [134, 178, 194],\n",
       "        [133, 177, 193],\n",
       "        [133, 177, 193]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [136, 183, 198],\n",
       "        [136, 183, 198],\n",
       "        ...,\n",
       "        [136, 178, 194],\n",
       "        [135, 177, 193],\n",
       "        [135, 177, 193]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [ 62,  79,  95],\n",
       "        [ 45,  62,  78],\n",
       "        ...,\n",
       "        [ 94, 108, 122],\n",
       "        [ 52,  66,  80],\n",
       "        [132, 146, 160]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [ 46,  63,  79],\n",
       "        [ 95, 112, 128],\n",
       "        ...,\n",
       "        [101, 115, 129],\n",
       "        [ 64,  78,  92],\n",
       "        [113, 127, 141]],\n",
       "\n",
       "       [[  0,   0,   0],\n",
       "        [ 93, 110, 126],\n",
       "        [124, 141, 157],\n",
       "        ...,\n",
       "        [ 43,  57,  71],\n",
       "        [ 24,  38,  52],\n",
       "        [ 59,  73,  87]]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('frame',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch 1.3",
   "language": "python",
   "name": "pytorch1.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
